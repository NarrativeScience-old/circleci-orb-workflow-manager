description: Wait in a workflow queue until the job is at the front
parameters:
  lock_key_env_var_name:
    description: |
      Environment variable containing the key of the workflow lock
      to acquire. This should generally be set in a Context.
    type: env_var_name
    default: WORKFLOW_LOCK_KEY
  wait_for:
    description: How long to wait before giving up (in minutes)
    type: integer
    default: 240
  ttl:
    description: |
      TTL of the workflow item in the store specified as a date string.
      See http://man7.org/linux/man-pages/man1/date.1.html#DATE_STRING for the format
      and https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/howitworks-ttl.html
      for how DynamoDB manages TTL.
    type: string
    default: "7 days"
  poll_interval:
    description: Polling interval between attempts to continue the workflow (in seconds)
    type: integer
    default: 10
  check_previous_commit:
    description: |
      Whether to check if the previous commit has been added to the queue before
      continuing with the workflow. This helps deal with the race condition of two
      commits getting merged seconds apart.
    type: boolean
    default: false
  force:
    description: |
      Whether to continue on with the workflow regardless of if another workflow is
      running
    type: boolean
    default: false
  do_not_cancel_workflow_if_tag_in_commit:
    description: |
      Do not allow this workflow to self-cancel, even if it could have been ignored, if
      the provided tag is in the commit message (case-insensitive)
    type: string
    default: ""
steps:
  - run:
      name: Wait in a workflow queue until the job is at the front
      command: |
        LOCK_KEY="${<< parameters.lock_key_env_var_name >>}"
        if [[ -z "$LOCK_KEY" ]]; then
          echo "No lock key set. Continuing..."
          exit 0
        fi

        MAX_ATTEMPTS="$(printf "%.0f" $((60 * << parameters.wait_for >> / << parameters.poll_interval >>)))"

        # Unix timestamp of when the commit was committed
        COMMITTED_AT="$(git log -1 --format=%ct)"

        # Create the DynamoDB key object and persist to the workspace for
        # downstream jobs to source
        WORKFLOW_KEY="$(
          echo '{}' \
            | jq --arg k "$LOCK_KEY" '.key.S = $k' - \
            | jq --arg t "$COMMITTED_AT" '.committed_at.N = $t' -)"
        mkdir -p /tmp/workspace
        echo "$WORKFLOW_KEY" > /tmp/workspace/workflow-key.json

        PREV_COMMIT="$(git rev-parse $CIRCLE_SHA1^)"

        # Create a temporary file containing the new item value (JSON)
        ITEM="$(mktemp)"
        echo '{}' \
          | jq --arg k "$LOCK_KEY" '.key.S = $k' - \
          | jq --arg t "$COMMITTED_AT" '.committed_at.N = $t' - \
          | jq --arg t "$(date +%s)" '.created_at.N = $t' - \
          | jq --arg t "$(date -d '<< parameters.ttl >>' +%s)" '.expires_at.N = $t' - \
          | jq --arg n "$CIRCLE_BUILD_NUM" '.build_num.N = $n' - \
          | jq --arg c "$CIRCLE_SHA1" '.commit.S = $c' - \
          | jq --arg u "${CIRCLE_USERNAME:-unknown}" '.username.S = $u' - \
          | jq --arg id "$CIRCLE_WORKFLOW_ID" '.workflow_id.S = $id' - \
          | jq '.status.S = "QUEUED"' - \
          | jq '.state.M = {}' - \
          > "$ITEM"
        cat "$ITEM"

        # Add the item to the table
        aws dynamodb put-item \
          --table-name "$DYNAMODB_TABLE_WORKFLOWS" \
          --item "file://$ITEM"
        echo "Added commit ($CIRCLE_SHA1) to the queue"

        # Query the table to find the workflow with the single oldest committed_at
        # timestamp and with a status of running or queued
        function queryItems() {
          local values="$(
            echo '{":key": {"S": ""}, ":running": {"S": "RUNNING"}, ":queued": {"S": "QUEUED"}}' \
            | jq --arg k "$LOCK_KEY" '.[":key"].S = $k' -)"
          aws dynamodb query \
            --table-name "$DYNAMODB_TABLE_WORKFLOWS" \
            --key-condition-expression '#key = :key' \
            --filter-expression '#status IN (:running, :queued)' \
            --expression-attribute-names '{"#key": "key", "#status": "status"}' \
            --expression-attribute-values "$values"
        }

        function workflowForCommitExists() {
          (
            local commit="$1"
            local values="$(
              echo '{}' \
              | jq --arg k "$LOCK_KEY" '.[":key"].S = $k' - \
              | jq --arg c "$commit" '.[":commit"].S = $c' -)"
            local result="$(
              aws dynamodb query \
                --table-name "$DYNAMODB_TABLE_WORKFLOWS" \
                --index-name commit \
                --key-condition-expression '#key = :key AND #commit = :commit' \
                --expression-attribute-names '{"#key": "key", "#commit": "commit"}' \
                --expression-attribute-values "$values" \
                --max-items 1)"
            local count="$(echo "$result" | jq -r .Count -)"
            if [[ "$count" == 1 ]]; then
              echo "Workflow exists for commit $commit"
              exit 0
            else
              echo "Workflow does not yet exist for commit $commit"
              exit 1
            fi
          )
        }

        <<# parameters.check_previous_commit >>
        export CHECK_PREVIOUS_COMMIT=1
        <</ parameters.check_previous_commit >>

        # Check if this workflow is at the front of the queue
        function isWorkflowFrontOfQueue() {
          (
            # Check that previous commit was processed. This means it has an item in
            # the workflows table.
            #
            # Merged commits are in order, but they race to the point of acquiring the
            # "lock". That race involves CircleCI spinning up a container in their
            # distributed system. Therefore a commit that happened second -- but by
            # only a few seconds -- could "win" the race to acquire the lock first.
            # This is a safety mechanism to ensure that merged comments are processed
            # in the correct order.
            if [[ -n "$CHECK_PREVIOUS_COMMIT" ]]; then
              if ! workflowForCommitExists "$PREV_COMMIT"; then
                echo "The previous commit: $PREV_COMMIT was not found! Will wait for $PREV_COMMIT to deploy"
                exit 1
              fi
            fi

            local result="$(queryItems)"
            if [[ $? -ne 0 ]]; then
              echo "Failed to query for workflow items"
              exit 1
            fi
            local workflow_id="$(echo "$result" | jq -r .Items[0].workflow_id.S -)"
            local count="$(echo "$result" | jq -r .Count -)"
            if [[ "$workflow_id" == "$CIRCLE_WORKFLOW_ID" || "$count" == 0 ]]; then
              echo "This workflow ($CIRCLE_WORKFLOW_ID) is front of the queue!"
              exit 0
            else
              echo "This workflow ($CIRCLE_WORKFLOW_ID) is not at the front of the queue. Next up: $(echo "$result" | jq .Items[0] -)"
              exit 1
            fi
          )
        }

        # Check if this workflow is at the end of the queue
        function isWorkflowEndOfQueue() {
          (
            # Check to see if this commit is at the end of the queue or if another
            # commit is pending that will deploy these changes.

            local result="$(queryItems)"
            if [[ $? -ne 0 ]]; then
              echo "Failed to query for workflow items"
              exit 1
            fi

            # Get the last workflow_id in the queue
            local workflow_id="$(echo "$result" | jq -r .Items[-1].workflow_id.S -)"
            local count="$(echo "$result" | jq -r .Count -)"
            echo "There are $count items (including this one) currently in the queue"

            if [[ "$workflow_id" == "$CIRCLE_WORKFLOW_ID" || "$count" == 0 ]]; then
              echo "This workflow ($CIRCLE_WORKFLOW_ID) is the last in the queue."
              exit 0
            else
              echo "This workflow ($CIRCLE_WORKFLOW_ID) is not at the end of the queue. Last Commit in the Queue is:"
              echo "$(echo "$result" | jq .Items[-1] -)"
              exit 1
            fi
          )
        }

        # Check if the commit is still the HEAD of the branch
        function isCommitHeadOfBranch() {
          (
            local head_sha="$(
              curl \
                --user "${GITHUB_USERNAME}:${GITHUB_PASSWORD}" \
                "https://api.github.com/repos/${CIRCLE_PROJECT_USERNAME}/${CIRCLE_PROJECT_REPONAME}/branches/${CIRCLE_BRANCH}" \
                --max-time 60 \
                --connect-timeout 60 \
              | jq -r '.commit.sha' -)"
            [[ "$CIRCLE_SHA1" == "$head_sha" ]]
          )
        }

        # Set a flag based on the commit message that determines if this commit can be
        # skipped if there are other commits behind it in the queue. By default the
        # commit will be skipped
        SKIP_COMMIT_ALLOWED=1
        <<# parameters.do_not_cancel_workflow_if_tag_in_commit >>
        MESSAGE="$(git log -1 --pretty=%B)"
        shopt -s nocasematch
        if [[ "$MESSAGE" == *'<< parameters.do_not_cancel_workflow_if_tag_in_commit >>'* ]]; then
          SKIP_COMMIT_ALLOWED=0
          echo "Skip is disabled" 
          echo "This Commit ($CIRCLE_SHA1) will not self-cancel and make $MAX_ATTEMPTS attempts to aquire the lock before failing"
        fi
        shopt -u nocasematch
        <</ parameters.do_not_cancel_workflow_if_tag_in_commit >>

        # Update the status of the workflow to RUNNING
        function updateWorkflowStatus() {
          local values="$(
            echo '{":status": {"S": "RUNNING"}}' \
              | jq --arg t "$(date +%s)" '.[":acquired_at"].N = $t' -)"

          aws dynamodb update-item \
            --table-name "$DYNAMODB_TABLE_WORKFLOWS" \
            --key "$WORKFLOW_KEY" \
            --update-expression 'SET #status = :status, #acquired_at = :acquired_at' \
            --expression-attribute-names '{"#status": "status", "#acquired_at": "acquired_at"}' \
            --expression-attribute-values "$values" \
            --return-values ALL_NEW
        }

        <<# parameters.force >>
        FORCE=1
        <</ parameters.force >>

        if [[ -n "$FORCE" ]]; then
          updateWorkflowStatus
          exit 0
        else
          n=1
          until [[ $n -gt "$MAX_ATTEMPTS" ]]; do
            echo "Attempt: $n of $MAX_ATTEMPTS"

            if [[ "$SKIP_COMMIT_ALLOWED" == 1 ]]; then
              # If this is not the last commit, then cancel
              # and assume the next deploy will cover these changes
              if isWorkflowEndOfQueue; then
                echo "This commit ($CIRCLE_SHA1) is last in the queue; Waiting to aquire the deployment lock"
              else
                echo 'export CANCEL_JOB=1' >> $BASH_ENV
                echo 'export WORKFLOW_LOCK_BUILD_STATUS=CANCELLED' >> $BASH_ENV
                echo "A newer commit has been added to the queue and is expected to deploy these changes"
                echo "This workflow ($CIRCLE_WORKFLOW_ID) will self-cancel and the commit ($CIRCLE_SHA1) will be squashed into the next"
                exit 0
              fi
            fi

            if isWorkflowFrontOfQueue; then
              updateWorkflowStatus
              echo "This commit ($CIRCLE_SHA1) has aquired the lock"
              
              # Check if this is the head of the branch just to notify the user
              if isCommitHeadOfBranch; then
                echo "$CIRCLE_SHA1 is the head of $CIRCLE_BRANCH"
              else
                echo "$CIRCLE_SHA1 is NOT the head of $CIRCLE_BRANCH."
                echo "This is okay and could be the case if squashing is disabled or your pipeline filters out some commits."
              fi

              exit 0
            fi

            sleep << parameters.poll_interval >>
            n=$[$n+1]
          done

          echo "Failed to acquire lock"
          exit 1
        fi

  - persist_to_workspace:
      root: /tmp/workspace
      paths:
        - workflow-key.json
